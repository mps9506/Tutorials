[
["index.html", "Practical R Applications in Water Resources Prerequisites Install R Install RStudio Familiarity with R and RStudio Suggested Packages Contributions and Editing", " Practical R Applications in Water Resources Michael Schramm 2020-09-25 Prerequisites This is not intended to be a primer or introduction to programming or R. Instead, this is a cookbook of sorts to help guide users to applying R in the context of our water resources work. External resources for those interested in the basics are provided below (Familiarity with R and RStudio). A few things required before getting started… Install R Download and install the newest version of R for your platform at: https://cloud.r-project.org/. For Windows: click on “Download R for Windows” click on “base” click the download link at the top of the page open the downloaded R-4.x.x.exe file and follow the prompts For macOS: click on “Download R for (Mac) OS X” Under “Latest release:” click on R-4.x.x.pkg For Linux: click “Download R for Linux” and choose the appropriate distribution Install RStudio Install the latest version of Rstudio Desktop for your platform at: https://rstudio.com/products/rstudio/download/#download Familiarity with R and RStudio This text assume some basic familiarity with R and RStudio. At minimum you should know how to start a project in RStudio, have a basic understanding of R packages and functions… If you are completely new to using R I recommend a few resources below: https://tinystats.github.io/teacups-giraffes-and-statistics/ - Great if you are completely new to programming, also provides some foundational stats training. https://rstudio.cloud/learn/primers - This provides self-paced, interactive, fundamental R programming exercises. Adventures in R - Another self-paced set of videos and excercies. This has a good introduction to the RStudio IDE. Suggested Packages This text will use the tidyverse set of packages throughout. install.pacakges(&quot;tidyverse&quot;) Sections on spatial analysis will utilize sf and raster. install.pacakges(c(&quot;sf&quot;, &quot;raster&quot;)) Contributions and Editing This text is rendered using bookdown and GitHub Actions (Xie 2016). This means you can submit issues, add code, or copy and render the book on your own system. The project is located on GitHub. If you clone the project into your RStudio session, the book can be rendered as local website using: bookdown::render_book(&quot;index.Rmd&quot;) Navigate to the \\_book subdirectory and open index.html to see the book. Furthermore, a pdf copy of the book can be generated using: bookdown::render_book(&quot;index.Rmd&quot;, &quot;bookdown::pdf_book&quot;) Navigate to the \\_book subdirectory and open book.pdf. References "],
["data.html", "Chapter 1 Loading and Formatting Data 1.1 Rectangular data 1.2 Formatting Data 1.3 USGS and EPA Data 1.4 Online Data Sources 1.5 Project Workflows", " Chapter 1 Loading and Formatting Data Load required packages: library(tidyverse) Text files (csv, delimited, ) Excel Relational databases Stat software (SAS SPSS Stata) Spatial (shapefiles, raster, etc) Reading data into R is generally the first step in any project workflow. The easiest format to get data into R is from a .csv or similar text file. However, there are functions to read data from Excel, relational databases, and some proprietary statistical software packages. There are also functions for readining in spatial data such as shapefiles or raster files, this is covered in … 1.1 Rectangular data Rectangular data generally refers to data stored as a table, rows and columns, or matrix. This is probably the most typical format of data we are reading into R. This data most often comes by way of text files or Excel spreadsheets. The readr package includes several functions for handling text files: read_csv: reads comma separated files, read_tsv: reads tab seperated files, read_delim: reads any formatted text file with a specified field separator. The example below is reading in a TCEQ SWQMIS generated datafile. The fields in the file are pipe seperated (|). Notice you are not limited to local filenames, you can point to files with a valid URL address. By default, readr tries to guess the variable type for each column. It is tedious, but I suggest specifying the column type with the col_type argument to prevent any errors. You can also skip importing certain columns if you choose. This can help speed things up if you are reading in a really large dataset. df &lt;- read_delim(file = &quot;https://gist.githubusercontent.com/mps9506/004624b5aa9bdf101c36278835cb38df/raw/46267d403bb450da4f7a0c726bd77d4fff1c5be5/1501_Bacteria.txt&quot;, delim = &quot;|&quot;, col_types = cols( `RFA(Sample Set ID)/Tag_id` = col_character(), Segment = col_character(), `Station ID` = col_character(), `Station Description` = col_character(), `Parameter Code` = col_character(), `Parameter Description` = col_character(), `Greater Than/Less Than` = col_skip(), Value = col_double(), `End Date` = col_date(format = &quot;%m/%d/%Y&quot;), `End Time` = col_skip(), `End Depth` = col_skip(), `Start Date` = col_skip(), `Start Time` = col_skip(), `Start Depth` = col_skip(), `Composite Category` = col_skip(), `Composite Type` = col_skip(), `Submitting Entity` = col_character(), `Collecting Entity` = col_character(), `Monitoring Type` = col_character(), Comments = col_character()) ) df ## # A tibble: 122 x 12 ## `RFA(Sample Set… Segment `Station ID` `Station Descri… `Parameter Code` ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1549521 1501 12515 TRES PALACIOS C… 31701 ## 2 R201391 1501 12515 TRES PALACIOS C… 31701 ## 3 R212883 1501 12515 TRES PALACIOS C… 31701 ## 4 L080888 1501 12515 TRES PALACIOS C… 31701 ## 5 L083338 1501 12515 TRES PALACIOS C… 31701 ## 6 L086380 1501 12515 TRES PALACIOS C… 31701 ## 7 L086923 1501 12515 TRES PALACIOS C… 31701 ## 8 L087695 1501 12515 TRES PALACIOS C… 31701 ## 9 L092047 1501 12515 TRES PALACIOS C… 31701 ## 10 10231848 1501 12515 TRES PALACIOS C… 31701 ## # … with 112 more rows, and 7 more variables: `Parameter Description` &lt;chr&gt;, ## # Value &lt;dbl&gt;, `End Date` &lt;date&gt;, `Submitting Entity` &lt;chr&gt;, `Collecting ## # Entity` &lt;chr&gt;, `Monitoring Type` &lt;chr&gt;, Comments &lt;chr&gt; The read_delim and related functions will produce an object called a tibble. When you print a tibble to the console, it provides the column names, variable types, and an abbreviated snapshot of the first few rows of data. 1.2 Formatting Data Most analysis and plotting functions in R prefer something called tidy data. The concept of tidy data can be difficult to grasp since we often don’t record data in a tidy format. Table ?? is an example of how data is often recorded in a spreadsheet. Notice there is a row for each date, then columns that have values for each water quality parameter and flow. Table 1.1: Example of wide data format Date Flow Nitrogen Phosphorus Ecoli 2020-01-01 130 0.31 0.03 189 2020-01-16 73 0.14 0.00 146 2020-01-31 212 0.08 0.01 893 2020-02-15 2259 0.15 0.02 77 2020-03-01 122 0.17 0.01 122 Tidy data is also called long data. The goal is to get one observation per row and a column for every covariate. In this case, we can tidy the data into four columns: Date, Flow Value, Parameter Name, and Parameter Value (Table ??. The observation of interest is the Parameter_Value which has a unique observation for each row. Date, Flow, and Parameter_name are not unique observations any longer. ## # A tibble: 15 x 4 ## Date Flow Parameter_Name Parameter_Value ## &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2020-01-01 130 Nitrogen 0.31 ## 2 2020-01-01 130 Phosphorus 0.03 ## 3 2020-01-01 130 Ecoli 189 ## 4 2020-01-16 73 Nitrogen 0.14 ## 5 2020-01-16 73 Phosphorus 0 ## 6 2020-01-16 73 Ecoli 146 ## 7 2020-01-31 212 Nitrogen 0.08 ## 8 2020-01-31 212 Phosphorus 0.01 ## 9 2020-01-31 212 Ecoli 893 ## 10 2020-02-15 2259 Nitrogen 0.15 ## 11 2020-02-15 2259 Phosphorus 0.02 ## 12 2020-02-15 2259 Ecoli 77 ## 13 2020-03-01 122 Nitrogen 0.17 ## 14 2020-03-01 122 Phosphorus 0.01 ## 15 2020-03-01 122 Ecoli 122 Work through real world example 1.3 USGS and EPA Data USGS provides R functions to retrieve and load streamflow and water quality data directly to R through the dataRetrieval package (De Cicco et al. 2018). 1.4 Online Data Sources Use APIs (TWDB example) 1.5 Project Workflows Discuss project structure, storing raw data seperately, using scripts to download and save data locally one time, References "],
["summarize-and-visualize-data.html", "Chapter 2 Summarize and Visualize Data", " Chapter 2 Summarize and Visualize Data Here is a review of existing methods. "],
["methods.html", "Chapter 3 Methods", " Chapter 3 Methods We describe our methods in this chapter. "],
["applications.html", "Chapter 4 Applications 4.1 Example one 4.2 Example two", " Chapter 4 Applications Some significant applications are demonstrated in this chapter. 4.1 Example one 4.2 Example two "],
["final-words.html", "Chapter 5 Final Words", " Chapter 5 Final Words We have finished a nice book. "],
["references.html", "References", " References "]
]
